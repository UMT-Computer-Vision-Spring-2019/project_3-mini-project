{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Where's Waldo?\n",
    "\n",
    "Due Mar. 4th\n",
    "\n",
    "So far, we've mostly focused on using imagery to do stuff for which it is better suited than a human: calculating camera locations from imagery, finding an optimal projective transform to stitch images together, and (soon) we'll be doing \"structure from motion\" in which we create 3D models of the world from collections of 2D images.  These are tasks primarily based around measuring things and doing calculations.  On the other side of the coin is object recognition (identifying the semantic content of a scene), and the best contemporary computer vision algorithms do object recognition at roughly the level of a 2 year old human (with some exceptions).  For this (mini-)project, we're going to delve into a topic that sort of straddles the line between these two general realms of computer vision.\n",
    "\n",
    "As a motivating example, did you ever play the game Where's Waldo.  There are books filled with images like the following:\n",
    "<img src='waldo_1.jpg'>\n",
    "The objective, of course, is to find Waldo, the man in the red striped shirt and beanie wearing glasses.  He looks like this:\n",
    "<img src='waldo_template.jpg'>\n",
    "These scenes are (obviously) intended to have a bunch of visual clutter to make this task reasonably challenging.\n",
    "\n",
    "Your task will be to come up with an algorithm that locates the template image (Waldo's face) and the target image (the larger scene).  This is called *template matching*, and it's a primitive form of feature recognition.  \n",
    "\n",
    "## Implementation\n",
    "### Template Matching\n",
    "Template matching works in a way that is very similar to filtering:  slide the template image over every location in the target image, computing some sort of metric at each position.  In practice, one commonly used choice for an error metric is the one that you've already used for matching keypoint descriptors: z-normalized sum square error.  Another choice is [normalized cross-correlation](https://en.wikipedia.org/wiki/Cross-correlation#Normalization).  Once these metrics have been computed, simply find the argmin (for SSE) or argmax (for NCC), and this will be the location of the best match.  \n",
    "\n",
    "**Your task is to implement template matching.  Use 'waldo_template.jpg' as the template and 'waldo_1.jpg' as the target image.  Where's Waldo? **\n",
    "\n",
    "### Not so fast!!!  What about scale!\n",
    "Oh, no.  As it turns out, the template I've provided is not the same scale as the Waldo in the image.  To deal with this, you'll need to create an image pyramid for the template (See Szeliski 3.5, and [Mubarak Shah's lecture on this topic](https://www.youtube.com/watch?v=KO7jJt0WHag&feature=youtu.be)).  This essentially just means creating a sequence of downsampled images of the template, and trying each one in hopes that one of the resulting down-scaled templates matches the feature in the target image.  **Create a sequence of templates with which to perform feature matching, each one 1/2 the resolution of the previous (so 1/4 the total number of pixels).  To avoid aliasing, before downsampling perform a $\\sigma=1$ Gaussian Blur of the image.  Once you've built your image pyramid, find the argmin/max in 3 dimensions (u,v,template scale)**.\n",
    "\n",
    "## Generalization\n",
    "**Waldo appears in every Where's Waldo image (obviously).  Try using the same technique on 'waldo_2.jpg'.  Does the algorithm work?**  I confess that I pulled the image of waldo for the template directly from 'waldo_1.jpg', so for the correct scale, there is something close to an exact match (i.e. SSE=0).  However, Waldo, while easily recognizable to the human eye after undergoing the small scale deformations associated with artistic license, is not so easily recognizable via template matching.  We will return to a similar problem when discussing object recognition, and hopefully this example will motivate the need to come up with representations of objects (like Waldo) that are more robust.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math as math\n",
    "import skimage.io as img_io\n",
    "import skimage.filters as filters\n",
    "from skimage.transform import resize\n",
    "from skimage.feature import match_template\n",
    "from scipy.ndimage.filters import correlate\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "### INFO TO PLEASE TAKE INTO ACCOUNT ###\n",
    "# I did this project solo. I went to class to try to meet my partners on wednesday (I got snowed in Friday and couldn't \n",
    "# make it to class at all, and they didn't show up. I don't know either of them, as well as not knowing their last names \n",
    "# so I couldn't email them, and with no moodle page I couldn't find them that way either, so I took on the project solo.\n",
    "# To make up for that, I decided using libraries where possible would be the better route to actually having something that\n",
    "# would function, as well as not having to reuse code without permission from former group mates who made the code. This is\n",
    "# detailed slightly further below as well.\n",
    "\n",
    "\n",
    "img = img_io.imread(\"waldo_1.jpg\", as_gray=True)\n",
    "template = img_io.imread(\"waldo_template.jpg\", as_gray=True)\n",
    "\n",
    "#Build pyramid by hand rather than using skimage gaussian_pyramid function, as well as label for output\n",
    "#Used library functions for gaussian blur and resize as well for speed, and wasn't comfortable reusing code written by \n",
    "#previous group members since they did the convolution parts.\n",
    "pyramid = []\n",
    "pyramid.append((\"Template\",template))\n",
    "for i in range(1,4):\n",
    "    x = filters.gaussian(pyramid[i-1][1], sigma=1,multichannel=True)\n",
    "    x = resize(x,(math.floor(x.shape[0]/2),math.floor(x.shape[1]/2)))\n",
    "    pyramid.append((\"Downscale #\" + str(i),x))\n",
    "\n",
    "#Show image and show each step of the pyramid\n",
    "img_io.imshow(img)\n",
    "plt.show()\n",
    "for item in pyramid:\n",
    "    print(item[0]+\":\")\n",
    "    img_io.imshow(item[1])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#Using skimage template match since it is well implemented. Mine took a VERY long time, left as comment to show what I \n",
    "#attempted But used the library function for speed and corretness. The library function uses a \n",
    "#normalized cross-correlation so I needed to use argmax to get the guessed location. I generally code with the \n",
    "#philosophy generally knowing what it is doing is the goal, so it is better to use libraries and not reinvent the wheel \n",
    "#as long as you know the process, rather than having to know the specifics at all times.\n",
    "outputs = []\n",
    "for item in pyramid:\n",
    "    cmp = item[1]\n",
    "    guess = match_template(img, cmp)\n",
    "    ij = np.unravel_index(np.argmax(guess), guess.shape)\n",
    "    x, y = ij[::-1]\n",
    "    outputs.append((item[0],x,y))\n",
    "\n",
    "print(\"Guesses per comparison in x,y format from skimage correlation:\")\n",
    "for item in outputs:\n",
    "    print(item[0],\" Guess:\",item[1],\",\",item[2])\n",
    "    \n",
    "print(\"\\n Starting second correlation \\n\")\n",
    "#This is testing with scipy's correlate function instead and using sklearn to normalize to see if they are similar.\n",
    "outputs2 = []\n",
    "for item in pyramid:\n",
    "    cmp = item[1]\n",
    "    img = normalize(img)\n",
    "    cmp = normalize(cmp)\n",
    "    guess = correlate(img, cmp)\n",
    "    ij = np.unravel_index(np.argmax(guess), guess.shape)\n",
    "    x, y = ij[::-1]\n",
    "    outputs2.append((item[0],x,y))\n",
    "    \n",
    "\n",
    "    \n",
    "print(\"Guesses per comparison in x,y format from scipy correlation:\")\n",
    "for item in outputs2:\n",
    "    print(item[0],\" Guess:\",item[1],\",\",item[2])\n",
    "\n",
    "#Based on manually checking with several pyramids, looks like after being downscaled twice it finds Waldo (Downscale #2) from\n",
    "#the skimage template matching, but the scipy correlation isn't as accurate, while also taking significantly longer\n",
    "\n",
    "\n",
    "#Image dimensions\n",
    "# img_x = img.shape[0]\n",
    "# img_y = img.shape[1]\n",
    "\n",
    "# My attempt, extremely slow and not 100% sure if right\n",
    "# for item in pyramid:\n",
    "#     x_dim = item.shape[0]\n",
    "#     y_dim = item.shape[1]\n",
    "#     out = np.zeros((img_y - y_dim,img_x - x_dim))\n",
    "#     for i in range(img_y - y_dim):\n",
    "#         for j in range(img_x - x_dim):\n",
    "#             sum = 0.0\n",
    "#             for x in range(x_dim):\n",
    "#                 for y in range(y_dim):\n",
    "#                     sum += (img[i + x][j + y] - item[x][y])\n",
    "#             out[i][j] = sum\n",
    "#     print(\"Template Done\")\n",
    "#     min_ind = np.unravel_index(np.argmin(out, axis=None), out.shape)\n",
    "#     print(min_ind)\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
